{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "env: CMAKE_ARGS=\"-DGGML_BLAS=ON -DGGML_BLAS_VENDOR=OpenBLAS\"\n",
      "\n",
      "Requirement already satisfied: transformers in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.47.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.4-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from accelerate) (2.5.1+cu124)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.10.0->accelerate) (70.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 992.0/992.0 kB 23.5 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.29.1-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
      "Downloading kagglehub-0.3.4-py3-none-any.whl (43 kB)\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------  11.3/11.5 MB 58.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 51.6 MB/s eta 0:00:00\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: sentencepiece, pytz, tzdata, protobuf, pandas, kagglehub, accelerate, peft\n",
      "Successfully installed accelerate-1.2.0 kagglehub-0.3.4 pandas-2.2.3 peft-0.14.0 protobuf-5.29.1 pytz-2024.2 sentencepiece-0.2.0 tzdata-2024.2\n",
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cpu\n",
      "Requirement already satisfied: llama-cpp-python in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-cpp-python) (1.26.3)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-cpp-python) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.45.0-py3-none-win_amd64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bitsandbytes) (2.5.1+cu124)\n",
      "Requirement already satisfied: numpy in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bitsandbytes) (1.26.3)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->bitsandbytes) (70.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Downloading bitsandbytes-0.45.0-py3-none-win_amd64.whl (68.5 MB)\n",
      "   ---------------------------------------- 0.0/68.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 7.9/68.5 MB 48.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 27.3/68.5 MB 72.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 46.4/68.5 MB 79.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 65.8/68.5 MB 82.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 68.5/68.5 MB 75.3 MB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting jupyter\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting notebook (from jupyter)\n",
      "  Downloading notebook-7.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter)\n",
      "  Using cached nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter) (6.29.5)\n",
      "Collecting ipywidgets (from jupyter)\n",
      "  Using cached ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jupyterlab (from jupyter)\n",
      "  Downloading jupyterlab-4.3.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (1.8.9)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (8.30.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets->jupyter)\n",
      "  Using cached widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets->jupyter)\n",
      "  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-console->jupyter) (3.0.48)\n",
      "Requirement already satisfied: pygments in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-console->jupyter) (2.18.0)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx~=0.28.0 (from jupyterlab->jupyter)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyterlab->jupyter) (3.1.3)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
      "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter)\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyterlab->jupyter) (70.0.0)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert->jupyter)\n",
      "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter)\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert->jupyter) (2.1.5)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter)\n",
      "  Using cached mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter)\n",
      "  Downloading nbclient-0.10.1-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter)\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert->jupyter)\n",
      "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx~=0.28.0->jupyterlab->jupyter) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx~=0.28.0->jupyterlab->jupyter) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx~=0.28.0->jupyterlab->jupyter)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx~=0.28.0->jupyterlab->jupyter) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx~=0.28.0->jupyterlab->jupyter) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (308)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pywinpty>=2.0.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading pywinpty-2.0.14-cp312-none-win_amd64.whl.metadata (5.2 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.3)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert->jupyter)\n",
      "  Downloading fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from anyio->httpx~=0.28.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from anyio->httpx~=0.28.0->jupyterlab->jupyter) (4.12.2)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Downloading rpds_py-0.22.3-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
      "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading jupyterlab-4.3.2-py3-none-any.whl (11.7 MB)\n",
      "   ---------------------------------------- 0.0/11.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 3.7/11.7 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.7/11.7 MB 30.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.7/11.7 MB 29.2 MB/s eta 0:00:00\n",
      "Using cached nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "Downloading notebook-7.3.1-py3-none-any.whl (13.2 MB)\n",
      "   ---------------------------------------- 0.0/13.2 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 10.5/13.2 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.2/13.2 MB 48.5 MB/s eta 0:00:00\n",
      "Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "Using cached jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
      "Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Using cached mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "Downloading nbclient-0.10.1-py3-none-any.whl (25 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Using cached widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
      "Downloading fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Downloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
      "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Downloading pywinpty-2.0.14-cp312-none-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 70.9 MB/s eta 0:00:00\n",
      "Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rpds_py-0.22.3-cp312-cp312-win_amd64.whl (235 kB)\n",
      "Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: webencodings, fastjsonschema, widgetsnbextension, websocket-client, webcolors, uri-template, types-python-dateutil, tinycss2, soupsieve, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, pywinpty, python-json-logger, pycparser, prometheus-client, pandocfilters, overrides, mistune, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, json5, httpcore, fqdn, defusedxml, bleach, babel, attrs, async-lru, terminado, referencing, httpx, cffi, beautifulsoup4, arrow, jupyter-server-terminals, jsonschema-specifications, isoduration, ipywidgets, argon2-cffi-bindings, jupyter-console, jsonschema, argon2-cffi, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "Successfully installed argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 async-lru-2.0.4 attrs-24.2.0 babel-2.16.0 beautifulsoup4-4.12.3 bleach-6.2.0 cffi-1.17.1 defusedxml-0.7.1 fastjsonschema-2.21.1 fqdn-1.5.1 httpcore-1.0.7 httpx-0.28.1 ipywidgets-8.1.5 isoduration-20.11.0 json5-0.10.0 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.3.2 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab-widgets-3.0.13 mistune-3.0.2 nbclient-0.10.1 nbconvert-7.16.4 nbformat-5.10.4 notebook-7.3.1 notebook-shim-0.2.4 overrides-7.7.0 pandocfilters-1.5.1 prometheus-client-0.21.1 pycparser-2.22 python-json-logger-2.0.7 pywinpty-2.0.14 referencing-0.35.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.22.3 send2trash-1.8.3 soupsieve-2.6 terminado-0.18.1 tinycss2-1.4.0 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 widgetsnbextension-4.0.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack_data in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sahil malhotra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers sentencepiece protobuf accelerate kagglehub peft pandas\n",
    "# Windows\n",
    "%set_env CMAKE_ARGS = \"-DGGML_BLAS=ON -DGGML_BLAS_VENDOR=OpenBLAS\"\n",
    "%pip install llama-cpp-python  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu\n",
    "%pip install -U bitsandbytes\n",
    "%pip install --upgrade jupyter\n",
    "%pip install --upgrade ipywidgets\n",
    "# get command for your os here - https://pytorch.org/get-started/locally/#windows-pip\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hey! I have been feeling a bit down lately. I have no motivation to get any work done or keep up with my responsibilities. My relationships and career are suffering because of this. Sometimes I feel like it would be easier if I just didn't exist, like it would all be better if I was dead. Its been like this for months now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "MODEL_PATH = 'klyang/MentaLLaMA-chat-7B'\n",
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = LlamaForCausalLM.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=100)\n",
    "response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was what we originally planned to use. It was popular enough with multiple downloads and part of a larger mental health project called  MentaLLaM that seemed promising. Within that project this one seemed to be the most popular and most reccomended to use. However upon running this model, it takes way too long to generate any text output even on a 3080ti. Execution was cancelled after waiting for 10 minutes for a response since this would be too slow for any practical purposes any how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "tokenizer = BartTokenizer.from_pretrained('Tianlin668/MentalBART')\n",
    "model = BartForConditionalGeneration.from_pretrained('Tianlin668/MentalBART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full output: depression. Reasoning: The post mentions feeling down, lacking motivation, and experiencing a decline in relationships and career. The individual also expresses thoughts of wanting to not exist and feeling like it would be better if they were dead. These are common symptoms associated with depression, such as low mood, loss of interest, and suicidal ideation.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=2048)\n",
    "response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print('Full output: ' + response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is the smaller version of the original proposed model and works incredibly quickly, responding in just a few seconds. Unfortunately, this model is not what we were expecting as it is trained on providing diagnoses as opposed to responding as a therpist would. While this is incredibly cool and useful, its not exactly what we were looking for in terms of creating a mental health chat bot. This is likely going to be hard to fine-tune/train for our purpose. That said this does seem like a really useful diagnosis tool so perhaps there is potential to leverage this in our final solution somehow in tandem with another model that actually responds to tyhe patient as a therapist would. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftConfig, PeftModel\n",
    "\n",
    "base_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "adapter = \"GRMenon/mental-health-mistral-7b-instructv0.2-finetuned-V2\"\n",
    "\n",
    "token = \"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\"  # Replace with your actual token\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt }\n",
    "]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model,\n",
    "    add_bos_token=True,\n",
    "    trust_remote_code=True,\n",
    "    padding_side='left'\n",
    ")\n",
    "\n",
    "# Create peft model using base_model and finetuned adapter\n",
    "config = PeftConfig.from_pretrained(adapter)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n",
    " load_in_4bit=True,\n",
    " device_map='auto',\n",
    " torch_dtype='auto',\n",
    " token=token)\n",
    "model = PeftModel.from_pretrained(model, adapter)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(conversation=messages,\n",
    "  tokenize=True,\n",
    "  add_generation_prompt=True,\n",
    "  return_tensors='pt').to(device)\n",
    "output_ids = model.generate(input_ids=input_ids, max_new_tokens=512, do_sample=True, pad_token_id=2)\n",
    "response = tokenizer.batch_decode(output_ids.detach().cpu().numpy(), skip_special_tokens = True)\n",
    "\n",
    "# Model response: \n",
    "print(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authentication issue even though model is open source? License agreement has been accepted on hugging face - access token has been used. This model is not yet evaluated, can come back to debug and explore this in a follow up. See below for comparable model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d4f56e7c6def4d05b56029cc5889735f",
      "e7ee179bb4904d198025d9495a9b5522",
      "0cd011ff8b1f4a35ac629ebff1e6409a",
      "43e56df9bd334208a7247729fb13a29b",
      "39f3878f3e0746a3ab5134d1942d68c6",
      "ed21ee4712b24efba1ad43fbc37b3489",
      "e722a8ce2a9e4aafaaa1bffbc5e8194d",
      "aaf02b509b274a6f99a9a95922ad3316",
      "c662dbce851343a6939f036324c91c6a",
      "36161f121dd84794837704841eb03d3b",
      "75d7c2a10eed469985d0c699504b0567"
     ]
    },
    "executionInfo": {
     "elapsed": 1241,
     "status": "ok",
     "timestamp": 1731005529184,
     "user": {
      "displayName": "Sahil Malhotra",
      "userId": "08914037324470894376"
     },
     "user_tz": 300
    },
    "id": "s7zLXfXhh4sI",
    "outputId": "5dc5235d-7394-40ea-c13a-c531f569af97"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"prabureddy/Mental-Health-FineTuned-Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype='auto'\n",
    ").eval()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt content: \"hi\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt }\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')\n",
    "output_ids = model.generate(input_ids.to('cuda'), max_new_tokens=100).to(device)\n",
    "response = tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "# Model response: \"Hello! How can I assist you today?\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response is helpful and useful, though a bit slow. About a minute and a half run time to generate 100 tokens isn't terrible. Output is cut off mid way through though. Higher token sizes will take even more processing time. Running this model on a 3080ti. Running in the cloud on streamlit or other free resource would likely not have enough processing power for this to be in a useable state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"thrishala/mental_health_chatbot\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"thrishala/mental_health_chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "generate_ids = model.generate(**inputs, max_new_tokens=100)\n",
    "response = tokenizer.decode(generate_ids[0], skip_special_tokens=True)\n",
    "print('Full output: ' + response)\n",
    "print('Theraspist resonse: ' + response.split(prompt)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output responded appropriately, though this model was even slower taking about 3 minutes to generate 100 tokens and was still cut off at the end. This was again run on a 3080ti and therefor running for free on streamlit or some other free resource is likely not going to be a viable solution. Additionally this model seems to be completing text with a delimineter of [/inst] for instruction to distinguish between the patient and therapist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fadodr/finetuned_mental_health_therapy_original\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"fadodr/finetuned_mental_health_therapy_original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1731008279598,
     "user": {
      "displayName": "Sahil Malhotra",
      "userId": "08914037324470894376"
     },
     "user_tz": 300
    },
    "id": "amR_7XJ9weVM"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "generate_ids = model.generate(**inputs, max_new_tokens=100)\n",
    "response = tokenizer.decode(generate_ids[0], skip_special_tokens=True)\n",
    "print('Full output: ' + response)\n",
    "print('Theraspist resonse: ' + response.split(prompt)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model responed pretty quickly, taking only a few seconds on a 3080ti. This has postential in terms of performance, however the base model appeears to be more on text completion as opposed to response. The generated text is respondiong as a patient would, continuing the user's original input before outputting as a theapist would, seemingly at random. Thedelimiter to seperate the atcual therapist response compared to the text completion of the patient is a new line but the fact that we are wasting tokens to complete the patient input ios not useful. This could potentially be trained/fine-tuned further accordingly and has potential, though a better base model would be preffered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "\trepo_id=\"victunes/TherapyBeagle-11B-v2-GGUF\",\n",
    "\tfilename=\"TherapyBeagle-11B-v2-Q2_K.gguf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.create_chat_completion(\n",
    "\tmessages = [\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": prompt\n",
    "\t\t}\n",
    "\t]\n",
    ")\n",
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Initialize the model\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"victunes/TherapyBeagle-11B-v2-GGUF\",\n",
    "    filename=\"TherapyBeagle-11B-v2-Q2_K.gguf\",\n",
    ")\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = []\n",
    "\n",
    "def chat_with_model(prompt):\n",
    "    # Add the new user message to conversation history\n",
    "    conversation_history.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    })\n",
    "    \n",
    "    # Create chat completion with entire conversation history\n",
    "    response = llm.create_chat_completion(\n",
    "        messages=conversation_history\n",
    "    )\n",
    "    \n",
    "    # Extract and store the model's response\n",
    "    model_response = response['choices'][0]['message']['content']\n",
    "    \n",
    "    # Add the model's response to conversation history\n",
    "    conversation_history.append({\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": model_response\n",
    "    })\n",
    "    \n",
    "    return model_response\n",
    "\n",
    "# Example usage\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    request = user_input\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        break\n",
    "    \n",
    "    response = chat_with_model(user_input)\n",
    "    print(\"Request: \", request)\n",
    "    print(\"Assistant:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model require cpp processing and that is not an environment we could reasonably set up on streamlit as installing and compiling the cpp dependencies alone took over half an hour. Regardless, the model was run for experimentatioin purposes in case it was useable. Testing showed a relatively quick model, taking only a few seconds to respond as a therapist would, however mostly the output was about asking for more information and not reeally addressing anything that the patient mentioned in the prompt. This can be good to continue the conversation but may not be as useful in terms of helping the patient. More experimentation can be done here and its possible this model can be trained/fine-tuned accoridngly to be more useful. The quick response time shows some promise, though the complex cpp environmental set up could pose difficult. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below is code to download and extract the Kaggle Mental Health Conversations dataset for training and refinement of existing models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"thedevastator/nlp-mental-health-conversations\")\n",
    "source_filename = \"train.csv\"\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "new_csv_name = \"kaggle-therapy-conversations.csv\"\n",
    "\n",
    "patient_col='Context'\n",
    "therapist_col='Response'\n",
    "\n",
    "# Construct the source file path\n",
    "source_path = os.path.join(path, source_filename)\n",
    "\n",
    "# Define the destination path in the current working directory\n",
    "destination_path = os.path.join(os.getcwd(), new_csv_name)\n",
    "\n",
    "if not os.path.exists(destination_path):\n",
    "    # Copy the downloaded file to the new_csv_path\n",
    "\n",
    "    shutil.copyfile(source_path, destination_path)\n",
    "    print(f\"File copied to: {destination_path}\")\n",
    "else:\n",
    "    print(f\"File already exists at: {destination_path}\")\n",
    "\n",
    "df = pd.read_csv(destination_path)\n",
    "\n",
    "if patient_col not in df.columns or therapist_col not in df.columns:\n",
    "  raise ValueError(f\"CSV must contain '{patient_col}' and '{therapist_col}' columns\")\n",
    "\n",
    "conversations = list(zip(df[patient_col], df[therapist_col]))\n",
    "\n",
    "# Remove any rows where either text is NaN\n",
    "conversations = [(p, t) for p, t in conversations if pd.notna(p) and pd.notna(t)]\n",
    "\n",
    "# Print first few conversations to verify\n",
    "for i, (patient, therapist) in enumerate(conversations[:3]):\n",
    "  print(f\"\\nConversation {i + 1}:\")\n",
    "  print(f\"Patient: {patient}\")\n",
    "  print(f\"Therapist: {therapist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below is code to download and extract the daic-woz dataset. This process preoved to be incredibly slow despit the zip files only being a few MB in size. This limitation is likely due to poor resources and performance on the host machine that we are downloading from as opposed to my own internet conenction. Each zip file takes about 5 minutes to download. Leaving this running over night, some of the files have downloaded (370/492). Preprocessing and use for training and refinement of any model can happen once all files are fully downloaded, at the rate the download is taking this will likely need to left running for a full 24 hours or so, which was not originally accoutned for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1731006892837,
     "user": {
      "displayName": "Sahil Malhotra",
      "userId": "08914037324470894376"
     },
     "user_tz": 300
    },
    "id": "eajhZQrvCKHw"
   },
   "outputs": [],
   "source": [
    "zip_files = [\n",
    "    \"300_P.zip\",\n",
    "    \"301_P.zip\",\n",
    "    \"302_P.zip\",\n",
    "    \"303_P.zip\",\n",
    "    \"304_P.zip\",\n",
    "    \"305_P.zip\",\n",
    "    \"306_P.zip\",\n",
    "    \"307_P.zip\",\n",
    "    \"308_P.zip\",\n",
    "    \"309_P.zip\",\n",
    "    \"310_P.zip\",\n",
    "    \"311_P.zip\",\n",
    "    \"312_P.zip\",\n",
    "    \"313_P.zip\",\n",
    "    \"314_P.zip\",\n",
    "    \"315_P.zip\",\n",
    "    \"316_P.zip\",\n",
    "    \"317_P.zip\",\n",
    "    \"318_P.zip\",\n",
    "    \"319_P.zip\",\n",
    "    \"320_P.zip\",\n",
    "    \"321_P.zip\",\n",
    "    \"322_P.zip\",\n",
    "    \"323_P.zip\",\n",
    "    \"324_P.zip\",\n",
    "    \"325_P.zip\",\n",
    "    \"326_P.zip\",\n",
    "    \"327_P.zip\",\n",
    "    \"328_P.zip\",\n",
    "    \"329_P.zip\",\n",
    "    \"330_P.zip\",\n",
    "    \"331_P.zip\",\n",
    "    \"332_P.zip\",\n",
    "    \"333_P.zip\",\n",
    "    \"334_P.zip\",\n",
    "    \"335_P.zip\",\n",
    "    \"336_P.zip\",\n",
    "    \"337_P.zip\",\n",
    "    \"338_P.zip\",\n",
    "    \"339_P.zip\",\n",
    "    \"340_P.zip\",\n",
    "    \"341_P.zip\",\n",
    "    \"343_P.zip\",\n",
    "    \"344_P.zip\",\n",
    "    \"345_P.zip\",\n",
    "    \"346_P.zip\",\n",
    "    \"347_P.zip\",\n",
    "    \"348_P.zip\",\n",
    "    \"349_P.zip\",\n",
    "    \"350_P.zip\",\n",
    "    \"351_P.zip\",\n",
    "    \"352_P.zip\",\n",
    "    \"353_P.zip\",\n",
    "    \"354_P.zip\",\n",
    "    \"355_P.zip\",\n",
    "    \"356_P.zip\",\n",
    "    \"357_P.zip\",\n",
    "    \"358_P.zip\",\n",
    "    \"359_P.zip\",\n",
    "    \"360_P.zip\",\n",
    "    \"361_P.zip\",\n",
    "    \"362_P.zip\",\n",
    "    \"363_P.zip\",\n",
    "    \"364_P.zip\",\n",
    "    \"365_P.zip\",\n",
    "    \"366_P.zip\",\n",
    "    \"367_P.zip\",\n",
    "    \"368_P.zip\",\n",
    "    \"369_P.zip\",\n",
    "    \"370_P.zip\",\n",
    "    \"371_P.zip\",\n",
    "    \"372_P.zip\",\n",
    "    \"373_P.zip\",\n",
    "    \"374_P.zip\",\n",
    "    \"375_P.zip\",\n",
    "    \"376_P.zip\",\n",
    "    \"377_P.zip\",\n",
    "    \"378_P.zip\",\n",
    "    \"379_P.zip\",\n",
    "    \"380_P.zip\",\n",
    "    \"381_P.zip\",\n",
    "    \"382_P.zip\",\n",
    "    \"383_P.zip\",\n",
    "    \"384_P.zip\",\n",
    "    \"385_P.zip\",\n",
    "    \"386_P.zip\",\n",
    "    \"387_P.zip\",\n",
    "    \"388_P.zip\",\n",
    "    \"389_P.zip\",\n",
    "    \"390_P.zip\",\n",
    "    \"391_P.zip\",\n",
    "    \"392_P.zip\",\n",
    "    \"393_P.zip\",\n",
    "    \"395_P.zip\",\n",
    "    \"396_P.zip\",\n",
    "    \"397_P.zip\",\n",
    "    \"399_P.zip\",\n",
    "    \"400_P.zip\",\n",
    "    \"401_P.zip\",\n",
    "    \"402_P.zip\",\n",
    "    \"403_P.zip\",\n",
    "    \"404_P.zip\",\n",
    "    \"405_P.zip\",\n",
    "    \"406_P.zip\",\n",
    "    \"407_P.zip\",\n",
    "    \"408_P.zip\",\n",
    "    \"409_P.zip\",\n",
    "    \"410_P.zip\",\n",
    "    \"411_P.zip\",\n",
    "    \"412_P.zip\",\n",
    "    \"413_P.zip\",\n",
    "    \"414_P.zip\",\n",
    "    \"415_P.zip\",\n",
    "    \"416_P.zip\",\n",
    "    \"417_P.zip\",\n",
    "    \"418_P.zip\",\n",
    "    \"419_P.zip\",\n",
    "    \"420_P.zip\",\n",
    "    \"421_P.zip\",\n",
    "    \"422_P.zip\",\n",
    "    \"423_P.zip\",\n",
    "    \"424_P.zip\",\n",
    "    \"425_P.zip\",\n",
    "    \"426_P.zip\",\n",
    "    \"427_P.zip\",\n",
    "    \"428_P.zip\",\n",
    "    \"429_P.zip\",\n",
    "    \"430_P.zip\",\n",
    "    \"431_P.zip\",\n",
    "    \"432_P.zip\",\n",
    "    \"433_P.zip\",\n",
    "    \"434_P.zip\",\n",
    "    \"435_P.zip\",\n",
    "    \"436_P.zip\",\n",
    "    \"437_P.zip\",\n",
    "    \"438_P.zip\",\n",
    "    \"439_P.zip\",\n",
    "    \"440_P.zip\",\n",
    "    \"441_P.zip\",\n",
    "    \"442_P.zip\",\n",
    "    \"443_P.zip\",\n",
    "    \"444_P.zip\",\n",
    "    \"445_P.zip\",\n",
    "    \"446_P.zip\",\n",
    "    \"447_P.zip\",\n",
    "    \"448_P.zip\",\n",
    "    \"449_P.zip\",\n",
    "    \"450_P.zip\",\n",
    "    \"451_P.zip\",\n",
    "    \"452_P.zip\",\n",
    "    \"453_P.zip\",\n",
    "    \"454_P.zip\",\n",
    "    \"455_P.zip\",\n",
    "    \"456_P.zip\",\n",
    "    \"457_P.zip\",\n",
    "    \"458_P.zip\",\n",
    "    \"459_P.zip\",\n",
    "    \"461_P.zip\",\n",
    "    \"462_P.zip\",\n",
    "    \"463_P.zip\",\n",
    "    \"464_P.zip\",\n",
    "    \"465_P.zip\",\n",
    "    \"466_P.zip\",\n",
    "    \"467_P.zip\",\n",
    "    \"468_P.zip\",\n",
    "    \"469_P.zip\",\n",
    "    \"470_P.zip\",\n",
    "    \"471_P.zip\",\n",
    "    \"472_P.zip\",\n",
    "    \"473_P.zip\",\n",
    "    \"474_P.zip\",\n",
    "    \"475_P.zip\",\n",
    "    \"476_P.zip\",\n",
    "    \"477_P.zip\",\n",
    "    \"478_P.zip\",\n",
    "    \"479_P.zip\",\n",
    "    \"480_P.zip\",\n",
    "    \"481_P.zip\",\n",
    "    \"482_P.zip\",\n",
    "    \"483_P.zip\",\n",
    "    \"484_P.zip\",\n",
    "    \"485_P.zip\",\n",
    "    \"486_P.zip\",\n",
    "    \"487_P.zip\",\n",
    "    \"488_P.zip\",\n",
    "    \"489_P.zip\",\n",
    "    \"490_P.zip\",\n",
    "    \"491_P.zip\",\n",
    "    \"492_P.zip\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "executionInfo": {
     "elapsed": 870629,
     "status": "error",
     "timestamp": 1731008263549,
     "user": {
      "displayName": "Sahil Malhotra",
      "userId": "08914037324470894376"
     },
     "user_tz": 300
    },
    "id": "UKBZW0_WDTDx",
    "outputId": "bb87ed8a-915c-4960-d930-ab2576261a3e"
   },
   "outputs": [],
   "source": [
    "# Daic-Woz download\n",
    "# Downloading all of these is incredibly slow. It only did like 10 after an hour \n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "# Base URL of your website\n",
    "base_url = 'https://dcapswoz.ict.usc.edu/wwwdaicwoz/'\n",
    "\n",
    "# Create a directory to save the files\n",
    "download_dir = 'daic-woz-file-zips'\n",
    "extract_dir = 'daic-woz-files'\n",
    "\n",
    "# Print current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Print full absolute path of download directory\n",
    "print(\"Download directory:\", os.path.abspath(download_dir))\n",
    "\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "if not os.path.exists(extract_dir):\n",
    "    os.makedirs(extract_dir)\n",
    "\n",
    "for file_name in zip_files:\n",
    "    download_path = os.path.join(download_dir, file_name)\n",
    "    extract_path = os.path.join(extract_dir, os.path.splitext(file_name)[0])\n",
    "    \n",
    "    # Check if both zip file and extracted directory already exist\n",
    "    if os.path.exists(download_path) and os.path.exists(extract_path):\n",
    "        print(f\"Skipping {file_name} - already downloaded and extracted\")\n",
    "        continue\n",
    "    \n",
    "    # Download only if zip file doesn't exist\n",
    "    if not os.path.exists(download_path):\n",
    "        url = f\"{base_url}{file_name}\"\n",
    "        print(f\"Downloading: {file_name}\")\n",
    "        response = requests.get(url)\n",
    "    \n",
    "        with open(download_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "            print(f\"Downloaded: {file_name}\")\n",
    "            \n",
    "    # Extract only if directory doesn't exist\n",
    "    if not os.path.exists(extract_path):\n",
    "        print(f\"Extracting: {file_name}\")\n",
    "        with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "            print(f\"Extracted: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOcUg4MF2h3Wj4vlU+fBeZ0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cd011ff8b1f4a35ac629ebff1e6409a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aaf02b509b274a6f99a9a95922ad3316",
      "max": 292,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c662dbce851343a6939f036324c91c6a",
      "value": 292
     }
    },
    "36161f121dd84794837704841eb03d3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39f3878f3e0746a3ab5134d1942d68c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43e56df9bd334208a7247729fb13a29b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36161f121dd84794837704841eb03d3b",
      "placeholder": "",
      "style": "IPY_MODEL_75d7c2a10eed469985d0c699504b0567",
      "value": "292/292[00:00&lt;00:00,4.76kB/s]"
     }
    },
    "75d7c2a10eed469985d0c699504b0567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aaf02b509b274a6f99a9a95922ad3316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c662dbce851343a6939f036324c91c6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4f56e7c6def4d05b56029cc5889735f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7ee179bb4904d198025d9495a9b5522",
       "IPY_MODEL_0cd011ff8b1f4a35ac629ebff1e6409a",
       "IPY_MODEL_43e56df9bd334208a7247729fb13a29b"
      ],
      "layout": "IPY_MODEL_39f3878f3e0746a3ab5134d1942d68c6"
     }
    },
    "e722a8ce2a9e4aafaaa1bffbc5e8194d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7ee179bb4904d198025d9495a9b5522": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed21ee4712b24efba1ad43fbc37b3489",
      "placeholder": "",
      "style": "IPY_MODEL_e722a8ce2a9e4aafaaa1bffbc5e8194d",
      "value": "generation_config.json:100%"
     }
    },
    "ed21ee4712b24efba1ad43fbc37b3489": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
